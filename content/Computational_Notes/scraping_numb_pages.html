---
title: "Scrape Numbered Pages"
date: "2020-03-22"
output: pdf_document
---



<p>Quick command to compile all links for a website that numbers its pages. Image I want to go to a website that contains 100 pages of reviews, the first 10 on page 1, the second 10 on page 2, the third 10 on page 3, etc. The first step is to create a vector or list of links to navigate to, one for each page.</p>
<p>The output I want is something like this…</p>
<pre class="r"><code>example_output &lt;- &#39;


https://www.indeed.com/jobs?q=data+science&amp;l=New+York%2C+NY
https://www.indeed.com/jobs?q=data+science&amp;l=New+York%2C+NY&amp;start=10
https://www.indeed.com/jobs?q=data+science&amp;l=New+York%2C+NY&amp;start=20
...


&#39;</code></pre>
<p>in which the first entry is page 1, the second page 2, and so on. There are three steps involved in this process:</p>
<ul>
<li><p>find url for the first page</p></li>
<li><p>discover how the url changes for each subsequent number</p></li>
<li><p>use a string command to compile the url’s.</p></li>
</ul>
<p>First, let’s say I want to scrape data from <a href="https://www.trustpilot.com/review/www.amazon.com">this website</a>, which has reviews across multiple pages. If I copy the url from the first page, and then copy the url from the second page, and the third page, I get…</p>
<pre class="r"><code>&#39;
https://www.trustpilot.com/review/www.amazon.com
https://www.trustpilot.com/review/www.amazon.com?page=2
https://www.trustpilot.com/review/www.amazon.com?page=3

&#39;</code></pre>
<p>So, the base url is the first link. Then, additional pages are coded as “?page=” and then the relevant number.</p>
<p>Second, find the last number. Let’s say it’s 20 in this case.</p>
<pre class="r"><code>last_number &lt;- 20</code></pre>
<p>Third, create a vector that compiles all of the links.</p>
<pre class="r"><code>library(tidyverse)
first_page &lt;- &quot;https://www.trustpilot.com/review/www.amazon.com&quot;
other_pages &lt;- str_c(first_page, &quot;?page=&quot;, 2:last_number)

review_pages &lt;- c(first_page, other_pages)
head(review_pages)</code></pre>
<pre><code>## [1] &quot;https://www.trustpilot.com/review/www.amazon.com&quot;       
## [2] &quot;https://www.trustpilot.com/review/www.amazon.com?page=2&quot;
## [3] &quot;https://www.trustpilot.com/review/www.amazon.com?page=3&quot;
## [4] &quot;https://www.trustpilot.com/review/www.amazon.com?page=4&quot;
## [5] &quot;https://www.trustpilot.com/review/www.amazon.com?page=5&quot;
## [6] &quot;https://www.trustpilot.com/review/www.amazon.com?page=6&quot;</code></pre>
<p>Here’s another example using Indeed. Notice that the values increase by 10 rather than 1.</p>
<pre class="r"><code>example_pages &lt;- &#39;

https://www.indeed.com/jobs?q=data+science&amp;l=New+York%2C+NY
https://www.indeed.com/jobs?q=data+science&amp;l=New+York%2C+NY&amp;start=10
https://www.indeed.com/jobs?q=data+science&amp;l=New+York%2C+NY&amp;start=20
https://www.indeed.com/jobs?q=data+science&amp;l=New+York%2C+NY&amp;start=30


&#39;

final_number &lt;- 100
all_vals &lt;- seq(from = 10, to = final_number, by = 10)

first_web &lt;- &quot;https://www.indeed.com/jobs?q=data+science&amp;l=New+York%2C+NY&quot;
other_webs &lt;- str_c(first_web, &quot;$start=&quot;, all_vals)

all_webs &lt;- c(first_web, other_webs)
head(all_webs)</code></pre>
<pre><code>## [1] &quot;https://www.indeed.com/jobs?q=data+science&amp;l=New+York%2C+NY&quot;         
## [2] &quot;https://www.indeed.com/jobs?q=data+science&amp;l=New+York%2C+NY$start=10&quot;
## [3] &quot;https://www.indeed.com/jobs?q=data+science&amp;l=New+York%2C+NY$start=20&quot;
## [4] &quot;https://www.indeed.com/jobs?q=data+science&amp;l=New+York%2C+NY$start=30&quot;
## [5] &quot;https://www.indeed.com/jobs?q=data+science&amp;l=New+York%2C+NY$start=40&quot;
## [6] &quot;https://www.indeed.com/jobs?q=data+science&amp;l=New+York%2C+NY$start=50&quot;</code></pre>
<p>Bo<span class="math inline">\(^2\)</span>m =)</p>
