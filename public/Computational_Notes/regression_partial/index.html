<!DOCTYPE html>
<html lang="en-US">

<head>
    <meta name="generator" content="Hugo 0.48" />
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Everything Partialled From Everything in Regression | Christopher Dishop</title>

     
      
    
    
    
    
    

  <meta name="author" content="">

 
    <meta property="og:title" content="Everything Partialled From Everything in Regression" />
<meta property="og:description" content="In regression, everything is partialled from everything. Let’s work through that notion with images and code. Imagine that emotion and ability cause an outcome, \(Y\).
What this image represents is that \(Y\) has variability (across people or time), and its variability is associated with variability in emotion and variability in ability. Notice that there is variability overlap between ability and \(Y\),
emotion and \(Y\),
emotion and ability,
and all three variables." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/computational_notes/regression_partial/" /><meta property="article:published_time" content="2019-04-19T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2019-04-19T00:00:00&#43;00:00"/> 
    



 
    
     
     
    
    
    <link rel="canonical" href="/computational_notes/regression_partial/">   <link rel="shortcut icon" type="image/png" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAMAAABEpIrGAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAABwlBMVEUAAAA/3MUK07UJ0rRk6NkC0rMAw5sAx6Ic1rs/3MYAlU0E0rQAhjMAyKIAiTkM07UJ07UAhC8m2L4o2L5O4Msn2L4AzKoAzq0128Mo2b8F0rQE0rMu2cAt2cAA0bI228MA0LAAy6kr2b8Q1LcF0rMH0rUAxp4t2b8c1ros2b8P1LcAzKsAzq4528Q02sIM07YAfyg93cUD0rMA0LEA0bFK4c0M1LcL07Uv2sEAzawY1rlJ4c0w2sEAzKkY1rqr+PQN07Yj170G0rQI07UF0bMt2cAF0rMC0bIL07UF0bMs2cAF0rMA0bIC0bIL07UF0rMA0bIA0bIA0bIO1LYr2b8N07Yp2L4F0rMF0rQJ07UA0bIC0bMA0bIH0rQK07UD0bMA0LAF0rMAyqYE0rMA0bIS1Lg228ID0bMM07YS1LcI07QL07UJ07UC0bMM07YG0rMS1Lc328IR1LcC0bIK07UM07Yo2L4P1LcL07UD0rMD0rMD0rMB0bIH0rQ23MMQ1LcD0rMN1LYB0LAJ0rQ33MMG0bMP1bgD0rMN07YH0rQH0rQ33MQF0rMD0rMN1LYo2L4F0rQG0rSA6tsA0bIB0bL////yxqscAAAAk3RSTlMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgnDXAUItvZKBAi6+vpMuf3++wEIAQcEBFn5AgR9UwMEoQLD/AEH4AIdAzha+UMEAQcc9AM4CAFSA9IC+4AEAc8yAwIEBAHOMQOBBLfLMAnFlAJNsa0LAAAAAWJLR0SVCGB6gwAAAAd0SU1FB+EBBBI4BduZ4woAAAF5SURBVDjLY2CAAUYmZgcWRydnVhc2dg4GTMAJlOdydZvs7sHtiU0FSJ7Hy3uyz2RfP24XNl4OLPJ8Xv5A+YBAsAo0M2DyQZMnY1fBL+AgCJXHrkIoWDgEJo9NhUioaBhCHqoiXExcAqZAMkIqckrU5MkoKqSjZeAmyMbIxSIZAFIRMCVOOl4epkAmQSERrwKOJMXkySl4rEhVSkufHDAZtyMzlDPdJweiyiN7UyRLIHsKQj5wMnowSIar5ExJQcjn5qnmqyFHlzqKL7EoQPMlphUaaL7EcGSBZiGKLzFUZGgVFSP5ElNFCVPpFORwhAeVto4uWEGwUJk3alSAVXhIR+tB7ShHTi5QkOIzpUKqEmKCPpODgReaipSUyVWl0tW6GEkWGhRBk2tq6wzrsSVqqPaGRqOmZmMTXWwqwNpbTFvbzMwtsGUMoPb2DqOmTksxK2xZLyhgck1XtzVIuw22zNszeXJvH0i7rR1G9gVlf/v+CRMnWaPYDgA74gwO0j2znAAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAxNy0wMS0wNFQxODo1NjowNSswMTowME2yC4wAAAAldEVYdGRhdGU6bW9kaWZ5ADIwMTctMDEtMDRUMTg6NTY6MDUrMDE6MDA877MwAAAAV3pUWHRSYXcgcHJvZmlsZSB0eXBlIGlwdGMAAHic4/IMCHFWKCjKT8vMSeVSAAMjCy5jCxMjE0uTFAMTIESANMNkAyOzVCDL2NTIxMzEHMQHy4BIoEouAOoXEXTyQjWVAAAAAElFTkSuQmCC">


    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css"> 
    <link rel="stylesheet" href="https://jenil.github.io/bulmaswatch/flatly/bulmaswatch.min.css"> 
    <link rel="stylesheet" href="/css/landing.css">   
    
    
</head>


<body>
    <header> <nav class="navbar is-transparent">
  <div class="navbar-brand">
    <a class="navbar-item" href="/">
      <img src="/img/bulma.png" alt="Bulma logo">
    </a>
  </div>
  
    
    
    
    <span class="nav-toggle">
        <span></span>
        <span></span>
        <span></span>
    </span>
    
    
    
    <div class="navbar-end">
      <div class="navbar-item">
        
        
          <a itemprop="url" class="navbar-item " href="/cv/"><span itemprop="name">CV</span></a>
        
          <a itemprop="url" class="navbar-item " href="/rec_reading/"><span itemprop="name">Recommended Reading</span></a>
        
          <a itemprop="url" class="navbar-item " href="/r_resources/"><span itemprop="name">R Resources</span></a>
        
          <a itemprop="url" class="navbar-item  is-active" href="/computational_notes/"><span itemprop="name">Computational_Notes</span></a>
        
      </div> 
    </div>
  </div>
</nav>
 </header>
    <main>

<div class="columns is-fullheight">
    <div class="column">
        <section class="hero is-default is-bold">
            <div class="hero-body">
                <div class="content container">
                   <p>In regression, everything is partialled from everything. Let’s work through that notion with images and code. Imagine that emotion and ability cause an outcome, <span class="math inline">\(Y\)</span>.</p>
<p><img src="partial_images/partial_variance.png" /></p>
<p>What this image represents is that <span class="math inline">\(Y\)</span> has variability (across people or time), and its variability is associated with variability in emotion and variability in ability. Notice that there is variability overlap between ability and <span class="math inline">\(Y\)</span>,</p>
<p><img src="partial_images/here1.png" /></p>
<p>emotion and <span class="math inline">\(Y\)</span>,</p>
<p><img src="partial_images/here2.png" /></p>
<p>emotion and ability,</p>
<p><img src="partial_images/here3.png" /></p>
<p>and all three variables.</p>
<p><img src="partial_images/here4.png" /></p>
<p>Once we regress <span class="math inline">\(Y\)</span> on emotion and ability, the regression coefficients represent the unique variance components of each predictor</p>
<p><img src="partial_images/partial_coefficients.png" /></p>
<p>but the technique also removes outcome-relevant variance</p>
<p><img src="partial_images/partial_no_middle.png" /></p>
<p>and overlapping variance in emotion and ability not related to the outcome.</p>
<p><img src="partial_images/partial_full_partial.png" /></p>
<p>So, in regression we get coefficients that represent the unique variance contribution of each predictor while partialling overlapping, outcome-relevant variance and overlapping, non-relevant variance. Emotion and ability get to account for their own causal effects of <span class="math inline">\(Y\)</span>, but neither predictor gets the overlapping variance in <span class="math inline">\(Y\)</span>, and the emotion and ability coefficients are adjusted for the emotion-ability overlap situated outside <span class="math inline">\(Y\)</span>.</p>
<p>Let’s do it with code.</p>
<p>Our sample contains 500 people with correlated emotion and ability (<span class="math inline">\(r\)</span> = 0.4).</p>
<pre class="r"><code>people &lt;- 500
emotion &lt;- rnorm(people, 0, 10)
ability &lt;- 0.4*emotion + rnorm(people, 0, 1) # could also do it with MASS</code></pre>
<p>Ability and emotion cause <span class="math inline">\(Y\)</span>.</p>
<pre class="r"><code>error &lt;- rnorm(people, 0, 1)
Y &lt;- 2 + 0.5*ability + 0.38*emotion + error</code></pre>
<p>Regression will recover the parameters.</p>
<pre class="r"><code>df &lt;- data.frame(
  &#39;emotion&#39; = c(emotion),
  &#39;ability&#39; = c(ability),
  &#39;y&#39; = c(Y)
)

summary(lm(y ~ ability + emotion,
           data = df))</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ ability + emotion, data = df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.0999 -0.6397  0.0183  0.6718  3.2326 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.00376    0.04376   45.79   &lt;2e-16 ***
## ability      0.46385    0.04189   11.07   &lt;2e-16 ***
## emotion      0.39235    0.01751   22.41   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9784 on 497 degrees of freedom
## Multiple R-squared:  0.9705, Adjusted R-squared:  0.9704 
## F-statistic:  8178 on 2 and 497 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Remember, each coefficient is consistent with the “lightning bolt” variance components above. Outcome-relevant overlap is removed and overlap between emotion and ability is removed. Since emotion and ability are partialled from each other, we won’t recover the 0.38 parameter relating emotion to <span class="math inline">\(Y\)</span> if we remove ability from the equation.</p>
<pre class="r"><code>summary(lm(y ~ emotion,
           data = df))</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ emotion, data = df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.1581 -0.6851 -0.0294  0.7663  3.8647 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 2.010911   0.048809    41.2   &lt;2e-16 ***
## emotion     0.579582   0.005074   114.2   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.091 on 498 degrees of freedom
## Multiple R-squared:  0.9632, Adjusted R-squared:  0.9632 
## F-statistic: 1.305e+04 on 1 and 498 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>How can we modify our variables to represent the “partialled multiple regression coefficient” for emotion? Naively, it seems that if we remove ability from <span class="math inline">\(Y\)</span> and then regress <span class="math inline">\(Y\)</span> on emotion we will recover the appropriate 0.38 parameter. Let’s try.</p>
<p>Regress <span class="math inline">\(Y\)</span> on just ability</p>
<pre class="r"><code>just_ability &lt;- lm(y ~ ability,
               data = df)</code></pre>
<p>and take the residuals, meaning that in our next regression we will examine the effect of emotion on “leftover <span class="math inline">\(Y\)</span>” – <span class="math inline">\(Y\)</span> with no influence from ability.</p>
<pre class="r"><code>y_with_ability_removed &lt;- resid(just_ability)
df$y_with_ability_removed &lt;- y_with_ability_removed

summary(lm(y_with_ability_removed ~ emotion,
           data = df))</code></pre>
<pre><code>## 
## Call:
## lm(formula = y_with_ability_removed ~ emotion, data = df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9454 -0.9496  0.0409  0.8816  4.4719 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.001691   0.060918  -0.028    0.978    
## emotion      0.026478   0.006333   4.181 3.43e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.362 on 498 degrees of freedom
## Multiple R-squared:  0.03391,    Adjusted R-squared:  0.03197 
## F-statistic: 17.48 on 1 and 498 DF,  p-value: 3.428e-05</code></pre>
<p>Nope. Why not? Think back to the diagrams, what we just assessed was</p>
<p><img src="partial_images/remove_ability.png" /></p>
<p>where the estimate accounts for the <span class="math inline">\(Y\)</span>-relevant overlap of emotion and ability, but it is wrong because it doesn’t account for the overlap between emotion and ability situated outside of <span class="math inline">\(Y\)</span>. In regression, everything is partialled from everything…we have not yet accounted for the overlap between emotion and ability in the space not in the <span class="math inline">\(Y\)</span> variance sphere. Now we will.</p>
<p>Partial ability from emotion</p>
<pre class="r"><code>emotion_with_ability_removed &lt;- resid(lm(emotion ~ ability,
                                         data = df))

df$emotion_with_ability_removed &lt;- emotion_with_ability_removed</code></pre>
<p>and now when we regress “Y with ability removed” on “emotion with ability removed” we will recover the 0.38 parameter.</p>
<pre class="r"><code>summary(lm(y_with_ability_removed ~ emotion_with_ability_removed,
           data = df))</code></pre>
<pre><code>## 
## Call:
## lm(formula = y_with_ability_removed ~ emotion_with_ability_removed, 
##     data = df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.0999 -0.6397  0.0183  0.6718  3.2326 
## 
## Coefficients:
##                               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                  1.050e-16  4.371e-02    0.00        1    
## emotion_with_ability_removed 3.924e-01  1.749e-02   22.43   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9775 on 498 degrees of freedom
## Multiple R-squared:  0.5025, Adjusted R-squared:  0.5015 
## F-statistic: 503.1 on 1 and 498 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>In regression, everything is partialled from everything.</p>
<p><img src="partial_images/partial_full_partial.png" /></p>
<p>The technique partials overlapping predictor variance both within and outside of the <span class="math inline">\(Y\)</span> space. Neither predictor accounts for overlapping variance within <span class="math inline">\(Y\)</span>, and if an important predictor is excluded then it will artificially account for variance it shouldn’t be capturing.</p>
<p>Note that all of this is relevant for III sums of squares…there are other approaches but III is by far the most common.</p>
<p>Bo<span class="math inline">\(^2\)</span>m =)</p>

                </div>
                <br>
            </div>
        </section>
    </div>
</div>
</main>
    <footer> 
  <footer class="footer">
    <div class="container">
        <div class="content has-text-centered">
            <p>
                I generated this site using 
                <a href="https://gohugo.io/">Hugo</a> and Jeblister's
                <a href="https://themes.gohugo.io/bulma/">Bulma</a> theme.
                
            </p>
            <p>
              Michigan State University is not liable for any opinions on this website.

            </p>
        </div>
    </div>
</footer>

<script src="//yihui.name/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<link rel="stylesheet" href="/css/obsidian.css" rel="stylesheet" id="theme-stylesheet">
<script src="/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script> 
</footer>

    <script async type="text/javascript" src="/js/bulma.js"></script>
    <script async type="text/javascript"  src="/js/clipboard.min.js"></script>
    <script async type="text/javascript"  src="/js/clip.js"></script>
</body>

</html>